{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825b0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb7c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a79026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_log_evaluate_word_analogies',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " '_upconvert_old_d2vkv',\n",
       " '_upconvert_old_vocab',\n",
       " 'add_lifecycle_event',\n",
       " 'add_vector',\n",
       " 'add_vectors',\n",
       " 'allocate_vecattrs',\n",
       " 'closer_than',\n",
       " 'cosine_similarities',\n",
       " 'distance',\n",
       " 'distances',\n",
       " 'doesnt_match',\n",
       " 'evaluate_word_analogies',\n",
       " 'evaluate_word_pairs',\n",
       " 'expandos',\n",
       " 'fill_norms',\n",
       " 'get_index',\n",
       " 'get_mean_vector',\n",
       " 'get_normed_vectors',\n",
       " 'get_vecattr',\n",
       " 'get_vector',\n",
       " 'has_index_for',\n",
       " 'index2entity',\n",
       " 'index2word',\n",
       " 'index_to_key',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'key_to_index',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'log_evaluate_word_pairs',\n",
       " 'mapfile_path',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'most_similar_to_given',\n",
       " 'n_similarity',\n",
       " 'next_index',\n",
       " 'norms',\n",
       " 'rank',\n",
       " 'rank_by_centrality',\n",
       " 'relative_cosine_similarity',\n",
       " 'resize_vectors',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'set_vecattr',\n",
       " 'similar_by_key',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'similarity_unseen_docs',\n",
       " 'sort_by_descending_frequency',\n",
       " 'unit_normalize_all',\n",
       " 'vector_size',\n",
       " 'vectors',\n",
       " 'vectors_for_all',\n",
       " 'vectors_norm',\n",
       " 'vocab',\n",
       " 'wmdistance',\n",
       " 'word_vec',\n",
       " 'words_closer_than']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea527ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72915095"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='great',w2='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa38525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43074462"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='great',w2='better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf10744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4098271"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='great',w2='well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6152a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These similarities are based upon the context in whoch these words appeared in the training documents. This similarity has nothing to do with \"Synonym\" of english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7747d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28772825"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='profit',w2='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9717a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34199455"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='profit',w2='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d541532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5829346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='profit',w2='revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed229af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291510105133057),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348341941833),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806034803390503),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709c13e",
   "metadata": {},
   "source": [
    "article1 =\"I was feeling good as it was holiday\"\n",
    "\n",
    "article2=\"I was feeling bad as it was holiday\"\n",
    "\n",
    "Here if we see the context in which 'good' and 'bad' are used in these 2 sentences is same...the neighbouring words for good/bad are almost same ...So based upon this, the two words are said to be similar in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24353c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.8680489659309387),\n",
       " ('puppy', 0.8106428384780884),\n",
       " ('pit_bull', 0.780396044254303),\n",
       " ('pooch', 0.7627376914024353),\n",
       " ('cat', 0.7609457969665527),\n",
       " ('golden_retriever', 0.7500901818275452),\n",
       " ('German_shepherd', 0.7465174198150635),\n",
       " ('Rottweiler', 0.7437615394592285),\n",
       " ('beagle', 0.7418621778488159),\n",
       " ('pup', 0.740691065788269)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9f1e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n",
       " ('dog', 0.760945737361908),\n",
       " ('kitten', 0.7464985251426697),\n",
       " ('feline', 0.7326234579086304),\n",
       " ('beagle', 0.7150582671165466),\n",
       " ('puppy', 0.7075453400611877),\n",
       " ('pup', 0.6934291124343872),\n",
       " ('pet', 0.6891531348228455),\n",
       " ('felines', 0.6755931973457336),\n",
       " ('chihuahua', 0.6709762215614319)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ae9a5",
   "metadata": {},
   "source": [
    " dog and cats mostly occurs in similar context in most of the articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ad550",
   "metadata": {},
   "source": [
    "King - man + woman = Queen\n",
    "\n",
    "France -Paris + Berlin = Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "256b7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"king\", \"woman\"],negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "165fba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Germany', 0.7901254892349243),\n",
       " ('Austria', 0.6026812195777893),\n",
       " ('German', 0.6004959940910339),\n",
       " ('Germans', 0.5851002931594849),\n",
       " ('Poland', 0.5847075581550598),\n",
       " ('Hungary', 0.5271855592727661),\n",
       " ('BBC_Tristana_Moore', 0.5249711275100708),\n",
       " ('symbol_RSTI', 0.5245768427848816),\n",
       " ('Belgium', 0.5221248269081116),\n",
       " ('Germnay', 0.5199405550956726)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"France\", \"Berlin\"],negative=[\"Paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc94f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jharkhand', 0.6881963610649109),\n",
       " ('Karnataka', 0.6507984399795532),\n",
       " ('Jamshedpur', 0.6432908177375793),\n",
       " ('Andhra_Pradesh', 0.6432713270187378),\n",
       " ('Uttar_Pradesh', 0.639927327632904),\n",
       " ('Madhya_Pradesh', 0.6392531991004944),\n",
       " ('Chhattisgarh', 0.6388451457023621),\n",
       " ('Bihar', 0.6377339959144592),\n",
       " ('Orissa', 0.6325611472129822),\n",
       " ('Maharashtra', 0.6291553974151611)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"France\", \"Ranchi\"],negative=[\"Paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e32e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(['Apple','Cat','Google','tata Steel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59c5062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sparrow'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(['Dog','Cat','Lion','Sparrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4f090cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glv  = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a42be71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below results are given based upon training data from twitter so it may differ from waht we got from google news model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59b573c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.9648017287254333),\n",
       " ('day', 0.9533665180206299),\n",
       " ('well', 0.9503170847892761),\n",
       " ('nice', 0.9438973665237427),\n",
       " ('better', 0.9425962567329407),\n",
       " ('fun', 0.9418926239013672),\n",
       " ('much', 0.9413353800773621),\n",
       " ('this', 0.9387555122375488),\n",
       " ('hope', 0.9383506774902344),\n",
       " ('great', 0.9378516674041748)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18a59af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_matchsnt_match(\"banana grapes oranges human\".split(' '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
